---
title: |
  | \vspace{5cm} \LARGE{STAT428 Group6 Project Written Report}
author:
- Zepeng Xiao, zepengx2
- Shuo Gong, shuog2
- Xiaoping Hua, xh3
- Dongfan Li, dongfan2
- Sixin Ma, sixinma2
date: "April 28, 2019"
output:
  html_document:
    df_print: paged
subtitle: Simulating NBA Match Results and Predicting NBA Playoff Teams
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\centerline{Abstract} 

\quad The main purpose of our project is simulating match results and predicting NBA playoff teams for season 2017-18 based on this season's real data, and comparing our results with this season's real data to calculate our method's accuracy, since analyzing and predictiong NBA stats is popular currently. The method we used in our project includes **Random number generations**, **Permutation test** and **Ridge regression**. 

\quad We found that regarding the playoff teams for season 2017-18, the accuracy of our prediction is $87.5 \% \ (14/16)$ when comapring the actual result. The result can be regarded as accurate beacuse we used each team's former performance in this season to make predictions, which is reliable. But there are still some conditions that were not included in the model, like player's injury, team's stamina and so on.

\pagebreak

# Introduction

```{r, fig.align="center",echo=FALSE,out.height='280px'}
knitr::include_graphics("eastandwest.jpg")
```


The National Basketball Association (NBA) is one of the most worldwide popular sporting events that is held every year in the world. 

* It has two conferences, East and West, with 15 teams in each division. 
* 30 teams fight in the league fight for a champion in a year-long season from October to June every year. 
* Each season is split into regular season and playoffs. 
* Each team has 82 matches to play in their regular season 
* Teams in the same conference would play more often than those.
* Only the top 8 teams in each division are able to enter the playoffs of the season. 
* Ranks are determined ascending by a special statistic called Games Behind:
  + When team a is the leading team of the conference.
\[Team B’s games behind=\frac {(Team A’s Wins-Team A’s Losses)-(Team B’s Wins-Team B’s Losses)}{2}\]


Thus which 16 teams would enter the playoffs every season is one of the biggest mystery in NBA every season.

Our goal, as introduced above, is simulating match results and predicting NBA playoff teams. In other words, we are going to predict which eight teams in each conference would get the lowest games behind by the end of the regular season. 

The focus is on the past 17-18 season. We will try to predict based on prior part of this season’s real data, and comparing our results with this season’s real data in the rest season to calculate our method’s accuracy. If we found our prediction is reliable in this season, we have prepared data in the past 10 years for test and verification.

# Methods

## Processing Data

### Raw Data

Raw datasets we used in our project are "2017-18_standing.csv" and "2017-18_teamBoxScore.csv", whose details are showed below:
```{r,echo=FALSE}
standing_data=read.csv("2017-18_standings.csv")
match_data=read.csv("2017-18_teamBoxScore.csv")
```
From 2017-18_standing.csv
```{r, echo = FALSE}
head(standing_data[,c(1,2,13,14,15,16,17,18,20,21)], 3)
```
From 2017-18_teamBoxScore.csv
```{r, echo = FALSE}
head(match_data[,c(1,10,11,13,14,17,73)], 3)
```

### Processing data to fit models

```{r, echo = FALSE, cache = TRUE}
data_standings = read.csv("2017-18_standings.csv")
data_boxscore = read.csv("2017-18_teamBoxScore.csv")
data_boxscore_total = read.csv("nba-enhanced-stats/2012-18_teamBoxScore.csv")
team_level = data_standings$teamAbbr[1:30]

data_hist = matrix(NA, 900, 5)
data_hist = as.data.frame(data_hist)
colnames(data_hist) = c("team1", "team2", "hist_win", "hist_lost", "hist_rate")

for (i in 1:30) {
  for (j in 1:30) {
    if (i != j) {
      data_hist[(i-1)*30 + j, 1] = as.character(team_level[i])
      data_hist[(i-1)*30 + j, 2] = as.character(team_level[j])
      totalResult1 = data_boxscore_total$teamRslt[which((data_boxscore_total$teamAbbr == team_level[i]) & (data_boxscore_total$opptAbbr == team_level[j]))]
      totalResult2 = data_boxscore_total$teamRslt[which((data_boxscore_total$teamAbbr == team_level[j]) & (data_boxscore_total$opptAbbr == team_level[i]))]
      totalGame = length(totalResult1) + length(totalResult2)
      totalWin = sum(as.numeric(totalResult1) - 1) + (length(totalResult2) - sum(as.numeric(totalResult2) - 1))
      totalLose = sum(as.numeric(totalResult2) - 1) + (length(totalResult1) - sum(as.numeric(totalResult1) - 1))
      data_hist[(i-1)*30 + j, 3] = totalWin
      data_hist[(i-1)*30 + j, 4] = totalLose
      data_hist[(i-1)*30 + j, 5] = totalWin / totalGame
    }
  }
}

data_hist = data_hist[!is.na(data_hist$team1),]

startMatchfit = min(which(data_boxscore$gmDate == "2017-12-01"))
endMatchfit = max(which(data_boxscore$gmDate == "2018-03-11"))

data_fit = as.data.frame(matrix(NA, endMatchfit - startMatchfit + 1, 9))
data_fit[,1] = data_boxscore$gmDate[startMatchfit:endMatchfit]
data_fit[,2] = data_boxscore$teamAbbr[startMatchfit:endMatchfit]
data_fit[,3] = data_boxscore$opptAbbr[startMatchfit:endMatchfit]
for (i in 1:nrow(data_fit)) {
  data_fit[i,4] = data_standings$homeWin[which(data_standings$stDate == data_fit[i,1] & data_standings$teamAbbr == data_fit[i, 2])] / 
    (data_standings$homeLoss[which(data_standings$stDate == data_fit[i,1] & data_standings$teamAbbr == data_fit[i, 2])] +
       data_standings$homeWin[which(data_standings$stDate == data_fit[i,1] & data_standings$teamAbbr == data_fit[i, 2])])
  data_fit[i,5] = data_standings$homeWin[which(data_standings$stDate == data_fit[i,1] & data_standings$teamAbbr == data_fit[i, 3])] / 
    (data_standings$homeLoss[which(data_standings$stDate == data_fit[i,1] & data_standings$teamAbbr == data_fit[i, 3])] +
       data_standings$homeWin[which(data_standings$stDate == data_fit[i,1] & data_standings$teamAbbr == data_fit[i, 3])])
  data_fit[i,6] = data_standings$lastTen[which(data_standings$stDate == data_fit[i,1] & data_standings$teamAbbr == data_fit[i, 2])] / 10
  data_fit[i,7] = data_standings$lastTen[which(data_standings$stDate == data_fit[i,1] & data_standings$teamAbbr == data_fit[i, 3])] / 10
  data_fit[i,8] = data_hist$hist_rate[which(data_hist$team1 == as.character(data_fit[i,2]) & data_hist$team2 == as.character(data_fit[i, 3]))]
}
colnames(data_fit) = c("gmDate", "homeTeam", "awayTeam", "homeTeamRate", "awayTeamRate", "homeTeamlast10", "awayTeamlast10", "histRate", "Result")
data_fit[,9] = data_boxscore$teamRslt[startMatchfit:endMatchfit]
#data_fit[,4] = as.numeric(data_fit[,4]) - 1
glm1 = glm(Result ~ homeTeamRate + awayTeamRate + homeTeamlast10 + awayTeamlast10 + histRate, family = binomial, data = data_fit)
```

In our project, we used actual match result from *2017-12-01* to *2018-03-11* to fit a model, and used this model to predict match result from *2018-03-12* to the end of NBA 2017-18 regular season since:

- At the beginning of the semester, each team's winning rate changed rapidly since the number of game played is small, which may be outliers for our fitted model.
- We can make more reliable prediction if we use the data in the same season.

The fitted data is showed below:
```{r, echo = FALSE}
head(data_fit, 3)
```
Some important columns' meaning: 

* "gmDate": Game date
* "homeTeam" / "awayTeam": The Abbreviation of home team name/away team name
* "homeTeamRate": The winning rate when home team played at home
* "awayTeamRate": The winning rate when away team layed away
* "homeTeamlast10" / "awayTeamlast10": The winning rate of last 10 games for home team/away team
* "histRata": The historical rate when home team play against away team
* "Result": The result for the match

### Processing table_a and table_b

Since for simulation part, we have to update the teams' standing after each simulation and use updated data to simulate next match result. We decided to made two tables A and B to store the standing data of all teams (in A) and the match data of each matches (in B). Then use the "current" standing data in A to simulate upcoming matches in B and use the following match data to regenerate new standing data in A.

The following chart about how we use table_a and table_b is showed below (detailed information will be shown in *Simulation* part):

```{r, fig.align="center",echo=FALSE}
knitr::include_graphics("methods_flowchart.png")
```

```{r,echo=FALSE}
creattablea = function(standing,match,today){
  standing=standing_data[standing_data$stDate==today,]
  match=match[as.Date(as.character(match$gmDate), format="%Y-%m-%d")-
                  as.Date(as.character(today), format="%Y-%m-%d")<=0,]
  teamname=standing$teamAbbr
  confname=rep("",30)
  for(i in 1:30){
    confname[i]=as.character(match[head(which(match$teamAbbr==teamname[i]),n=1),]$teamConf)
  }
  homerate=standing$homeWin/(standing$homeLoss+standing$homeWin)
  homematch=(standing$homeLoss+standing$homeWin)
  awayrate=standing$awayWin/(standing$awayLoss+standing$awayWin)
  awaymatch=(standing$awayLoss+standing$awayWin)
  last10=standing$lastTen/10
  homescorewin=numeric(30)
  awayscorewin=numeric(30)
  homescorelost=numeric(30)
  awayscorelost=numeric(30)
  for(i in 1:30){
    tempmatch=match[match$teamAbbr==teamname[i],]
    homescorewin[i]=mean(tempmatch[tempmatch$teamLoc=="Home",]$teamPTS)
    awayscorewin[i]=mean(tempmatch[tempmatch$teamLoc=="Away",]$teamPTS)
    homescorelost[i]=mean(tempmatch[tempmatch$teamLoc=="Home",]$opptPTS)
    awayscorelost[i]=mean(tempmatch[tempmatch$teamLoc=="Away",]$opptPTS)
  }
  lastgame = match$teamLoc[1:30]#home or away
  numberdayoff=numeric(30)
  for(j in 1:10){
      assign(paste0("l", j), numeric(30))
    }
  for(i in 1:30){
    tempmatch=match[match$teamAbbr==teamname[i],]
    tempid=max(which(as.Date(as.character(tempmatch$gmDate), format="%Y-%m-%d")-
                  as.Date(as.character(today), format="%Y-%m-%d")<0))
    lastgame[i] = tempmatch[tempid,]$teamLoc
    
    lastgamedate = tempmatch[tempid,]$gmDate
    numberdayoff[i] = abs(as.Date(as.character(lastgamedate), format="%Y-%m-%d")-
                  as.Date(as.character(today), format="%Y-%m-%d"))
    
    last10match=rev(tail(tempmatch$teamRslt, 10))
    l1[i]=last10match[1]
    l2[i]=last10match[2]
    l3[i]=last10match[3]
    l4[i]=last10match[4]
    l5[i]=last10match[5]
    l6[i]=last10match[6]
    l7[i]=last10match[7]
    l8[i]=last10match[8]
    l9[i]=last10match[9]
    l10[i]=last10match[10]
    
  } 
  lastgame=as.character( lastgame)
  totalmatch=standing$gamePlay
  confmatch=standing$confWin+standing$confLoss
  confrate=standing$confWin/confmatch
  teamname=as.character(teamname)
  toreturn=data.frame(teamname,confname,homerate,awayrate,last10,homescorewin,homescorelost,awayscorewin,awayscorelost,confrate,numberdayoff,lastgame,totalmatch,confmatch,homematch, awaymatch, l1,l2,l3,l4,l5,l6,l7,l8,l9,l10)# homematch awaymatch last10result
  toreturn
}

tablea180311=creattablea(standing_data,match_data,"2018-03-11")

```
Basic information about table_a and table_b are as follows:

**Initial table_a:**
```{r}
str(tablea180311)
```
Columns’ meaning:

* "Teamname": Name of team
* "Confname": East or West, which defines which conference the team belongs to.
* "Homerate": winrate at home
* "Awayrate": winrate away
* "Last10": winrate in the last 10 matches
* "Homescorewin": score won when at home
* "Homescorelost": score lost when at home
* "Awayscorewin": score win when playing away home
* "Awayscorelost": score lost when to play away home
* "Confrate": winrate when playing within the conference
* "Numberdayoff": number of days since the last match
* "Lastgame": is the last game played at home or away
* "totalmatch":number of matches played
* "confmatch":number of matches played within conference
* "Homematch": number of matches played at home
* "Awaymatch": number of matches played away
* "l1" ~ "l10": is the last 1~10 win or lose

**Initial table_b:**
```{r, echo = FALSE, cache = TRUE}
data_boxscore = data_boxscore[data_boxscore$teamLoc == "Home",]
endMatch = max(which(data_boxscore$gmDate == "2018-04-11"))
startMatch = min(which(data_boxscore$gmDate == "2018-03-12"))
data_B = as.data.frame(matrix(NA, (endMatch - startMatch + 1), 56))
colnames(data_B) = c("gmDate", "HomeTeam(A)", "AwayTeam(B)", "SameConf", "HistData", 
                    "confname_A", "homerate_A", "awayrate_A", "last10_A", "homescorewin_A", "homescorelost_A", "awayscorewin_A", "awayscorelost_A",  "confrate_A", "numberdayoff_A", "lastgame_A", "totalmatch_A", "confmatch_A",
                    "homematch_A", "awaymatch_A", "l1_A", "l2_A", "l3_A", "l4_A", "l5_A", "l6_A", "l7_A", "l8_A", "l9_A", "l10_A", 
                    "confname_B", "homerate_B", "awayrate_B", "last10_B", "homescorewin_B", "homescorelost_B", "awayscorewin_B", "awayscorelost_B",  "confrate_B", "numberdayoff_B", "lastgame_B", "totalmatch_B", "confmatch_B", 
                    "homematch_B", "awaymatch_B", "l1_B", "l2_B", "l3_B", "l4_B", "l5_B", "l6_B", "l7_B", "l8_B", "l9_B", "l10_B","result")
data_B[, 1] = data_boxscore$gmDate[startMatch:endMatch]
data_B[, 2] = data_boxscore$teamAbbr[startMatch:endMatch]
data_B[, 3] = data_boxscore$opptAbbr[startMatch:endMatch]
data_B[, 4] = (data_boxscore$teamConf == data_boxscore$opptConf)[startMatch:endMatch]
for (i in 1:nrow(data_B)) {
  data_B[i, 5] = data_hist$hist_rate[which(data_hist$team1 == as.character(data_B[i,2]) & data_hist$team2 == as.character(data_B[i,3]))]
}
```

```{r}
str(data_B[,c(1,2,3,4,5,56)])
```
Columns’ meaning:

* "Hometeam(A)": The Abbreviation of team A (played as home team)
* "Awayteam(B)": The Abbreviation of team B (played as away team)
* "SameConf": True if two teams are in the same conference, false if not
* "HistData": The historical rate for team A played with team B
* "result": The match result based on our simulation
* The rest of columns are the data that is contained in table_a describing conditions for both team A and team B 

## Generalized Linear Regression

NBA is the place "where amazing happens", so instead of directly predicting match results by our model, we decided to predict the win probability for home team in each team and make simulation to take "amazing things" into consideration.

Therefore, we treated the match result between home team A and away team B as a bernoulli distribution with probability $P(Y_{AB} | X_{AB})$, where the win probability of home team A is $P(Y_{AB} | X_{AB})$ and the win probability for away team B is ($1 - P(Y_{AB} | X_{AB})$).

We use `glm()` function to predict our win probability, whose model is: $$P(Y_{AB} | X_{AB}) = \frac{e^{\pi(X_{AB})}}{1 + e^{\pi(X_{AB})}} \ \text{where} \ \pi(X_{AB}) = \beta_0 + \beta_1 x_{AB1} + \ldots + \beta_n x_{ABn}$$
$x_{AB1}, x_{AB2}, \ldots, x_{ABn}$ are predictor variables related to team A and team B.

When selecting predictors of our models, we think that the most significant factors that may affect match include the short-term performance and long-term performance for both teams in this season, and the historical performance between these two teams. Therefore, our results include predictors `homeTeamRate`, `awayTeamRate`, `homeTeamlast10`, `awayTeamlast10` and `histRate`. (The meaning of each predictors are defined preciously in **Processing Data** part).

The summary is showed below:
```{r, echo = FALSE}
summary(glm1)
glmcoe = glm1$coefficients
```
Hence our generalized model is: 
$$p(Y_{AB}) = \frac{e^{`r glmcoe[1]` + (`r glmcoe[2]`X_{AB1}) + (`r glmcoe[3]`X_{AB2}) + (`r glmcoe[4]`X_{AB3}) + (`r glmcoe[5]`X_{AB4}) + (`r glmcoe[6]`X_{AB5})}}{1 + e^{`r glmcoe[1]` + (`r glmcoe[2]`X_{AB1}) + (`r glmcoe[3]`X_{AB2}) + (`r glmcoe[4]`X_{AB3}) + (`r glmcoe[5]`X_{AB4}) + (`r glmcoe[6]`X_{AB5})}}$$
where $X_{AB1}$ is homeTeamRate, $X_{AB2}$ is awayTeamRate, $X_{AB3}$ is homeTeamlast10, $X_{AB4}$ is awayTeamlast10 and $X_{AB5}$ is histRate.

Though all predictors seem significant($\text{p-value} < 0.05$) in our generalized linear model, we still need to check if collinearity exists between some predictors. So we turn to permutation test for checking.

## Permutation Test

The generalized linear model we used to predict the game result includes predictors that might be correlated to each other. For example, `homeTeamRate` and `homeTeamlast10` seem to be positively correlated in common sense. Therefore, to improve our regression fit, we want to thorougly examine the correlations among the variables and proceed to use ridge regression if the variables are confirmed to be correlated. The variables for testing are,

* homeTeamRate
* awayTeamRate
* homeTeamlast10
* awayTeamlast10
* histRate

A permutation test essentially checks if X and Y have the same distribution by doing the following procedure,

1. Observe a test statistic for the null hypothesis, $H_0$
2. For each replicated $b = 1, 2,..., B$:
    - Generate a random permutation $\pi$
    - Generate a new test statistic from the random permutation
3. Get a Monte Carlo estimate of the p-value by calculating the probability of obtaining a new test statistic that is more extreme than the observed test statistic in the $B$ replicates
4. Reject $H_0$ at a significance level $\alpha$ if the p-value is less than $\alpha$.

In our case, we can inherit the idea of permutation test and adapt it to paired data to check the correlation in between. If there is truly no association between X and Y, the distribution of $(X_i, Y_{\pi(i)})$ will be the same as that of $(X_i, Y_i)$, where $\pi(i)$ is the $i$-th element of a permutation $\pi$ of ${1, 2, ..., 13}$. We implement this idea by randomly permuting Y and pairing it with a fixed X and get a p-value for testing $H_0: \rho = 0$ versus $H_1: \rho \neq 0$, where $\rho$ is either the Pearson correlation coefficient or the Spearman correlation coefficient:

- The *Pearson Method* evaluates the **linear** relationship between two continuous variables, where a change in one variable is associated with a **proportional** change in the other variable. 

- The *Spearman Method* is based on the ranked values for each variable rather than the raw data. It evaluates the **monotonic** relationship between two continuous or ordinal variables, where the variables tend to change together, but not necessarily at a constant rate. It is more general than the Pearson method. 

To determine which correlation coefficient to use for which pair of comparison, we plot variables against each another and added some noise using `jitter()` to visualize the trend of relationship and decide which method to use.

```{r, echo = FALSE}
data = read.csv("data_fit.csv")
# Scatterplots for Correlation
par(mfrow = c(2,2))
plot(data$homeTeamRate, jitter(data$homeTeamlast10, 3), main = "Home Rate vs. Home Last 10")
plot(data$awayTeamRate, jitter(data$awayTeamlast10, 3), main = "Away Rate vs. Away Last 10")
plot(data$homeTeamRate, data$histRate, main = "Home Rate vs. Historical Rate")
plot(data$awayTeamRate, data$histRate, main = "Away Rate vs. Historical Rate")
par(mfrow = c(2,2))
plot(jitter(data$homeTeamlast10, 3), data$histRate, main = "Home Last 10 vs. Historical Rate")
plot(jitter(data$awayTeamlast10, 3), data$histRate, main = "Away Last 10 vs. Historical Rate")
plot(data$homeTeamRate, data$awayTeamRate, main = "Home Rate vs. Away Rate")
plot(jitter(data$homeTeamlast10, 3), jitter(data$awayTeamlast10, 3), main = "Home Last 10 vs. Away Last 10")
par(mfrow = c(2,2))
plot(data$homeTeamRate, jitter(data$awayTeamlast10, 3), main = "Home Rate vs. Away Last 10")
plot(data$awayTeamRate, jitter(data$homeTeamlast10, 3), main = "Away Rate vs. Home Last 10")
```

According to the plots, *Home Rate vs. Home Last 10*, *Away Rate vs. Away Last 10*, *Home Last 10 vs. Historical Rate*, and *Away Last 10 vs. Historical Rate* appear to be linear. We use the Pearson method for these pairs. For the rest pairs, trends are not that obvious. Therefore, we use the more genearl Spearman method.

By performing permutation tests, we obtained the following table, which shows all the pairs we tested, the method we used, the p-value for the permutation test, and the decisions based on the p-values. 

| Pairs                            | Method   | p-value    | Decision       |
|----------------------------------|----------|------------|----------------|
| Home Rate vs. Home Last 10       | Pearson  | 9.999e-05  | Correlated     |
| Away Rate vs. Away Last 10       | Pearson  | 9.999e-05  | Correlated     |
| Home Rate vs. Historical Rate    | Spearman | 9.999e-05  | Correlated     |
| Away Rate vs. Historical Rate    | Spearman | 9.999e-05  | Correlated     |
| Home Last 10 vs. Historical Rate | Pearson  | 9.999e-05  | Correlated     |
| Away Last 10 vs. Historical Rate | Pearson  | 9.999e-05  | Correlated     |
| Home Rate vs. Away Rate          | Spearman | 0.4131587  | Not Correlated |
| Home Last 10 vs. Away Last 10    | Spearman | 9.999e-05  | Correlated     |
| Home Rate vs. Away Last 10       | Spearman | 0.02689731 | Correlated     |
| Away Rate vs. Home Last 10       | Spearman | 0.02329767 | Correlated     |

We found that all pairs of variables have correlation except *Home Rate vs. Away Rate*. This observation suggests that there exists problem of collinearity among the predictors. It leads us to further examine the VIF (Variance Inflation Factor) of the predictors and fit a Ridge Regression model to remedy the problem of collinearity. 

## Ridge Regression 

Ridge regression can be applied to significantly reduce prediction variance due to collinearity between predictors. For ridge regression, we have to find $\hat{\beta_{\text{ridge}}}$ to minimize the following function: $$\|y - X\beta\|^2 + \lambda\|\beta\|^2$$

Different $\lambda$ will make our $\hat{\beta_{\text{ridge}}}$ different, so we also have to find the best $\lambda$ to determine our best $\hat{\beta_{\text{ridge}}}$. The code for finding $\lambda$ is showed below:
```{r, echo = TRUE, eval = FALSE}
# finding best lambda in ridge regression method
Y = as.matrix(as.numeric(factor(data_fit$Result)))
X = as.matrix(data_fit[,-c(9, 1, 2, 3)])
rr = glmnet(X, Y, family = "binomial", alpha = 0)
cv.out = cv.glmnet(X, Y, alpha = 0)
bestlam = cv.out$lambda.min

# we can do the following to get our ridge regression prediction
predict.glmnet(rr, t(as.matrix(X[1,])))[which(cv.out$lambda == cv.out$lambda.min)]
```

```{r, echo = FALSE, cache = TRUE, message = FALSE}
library(glmnet)
Y = as.matrix(as.numeric(factor(data_fit$Result)))
X = as.matrix(data_fit[,-c(9, 1, 2, 3)])
rr = glmnet(X, Y, family = "binomial", alpha = 0)
cv.out = cv.glmnet(X, Y, alpha = 0)
bestlam = cv.out$lambda.min
#plot(cv.out$lambda, cv.out$cvm, type = "l", col = "dodgerblue")
```

Finally we found that the best lambda in our ridge regression is $`r bestlam`$, so we can use our ridge regression to predict the win probability and simulate the match result for each match.

## Simulation Process

We repeatedly predicted playoff teams 1000 times by simulating match results with the ridge regression model above. Given table A and table B data, we could write our simulation process algorithm as below:

1. Create two $1000\times8$ empty data frame, `sim_record_East` and `sim_record_West` to store top 8 eastern team and western team names for 1000 simulations. Also, create a $30\times10$ data frame `sim_record_number`, whose column names are `"teamname", "confname", "1st", "2nd", "3rd", "4th", "5th", "6th", "7th", "8th"`, to accumulately record how many times each team enters the top 8 after 1000 simulations. And columns from `1st` to `8th` are all initialized with zeros.
1. For each game match (each row is one game match) in table B:
    - Update standing data (columns from `confname_A` to `l10_B` in game match row) from the corresponding rows in table A.
    - Use updated game match data and our ridge regression model to predict the home team win probability. Using our ridge regression model, we could get  `predictStat`, and `threshold = exp(predictStat) / (1 + exp(predictStat))`. Then randomly generate one number from `runif(1)` and compare it with `threshold`. Home team wins if the number generated is less than `threshold`, and vice versa.
    - Once we get the predicted match result, we use it to update the corresponding data in table A, including `homerate`, `awayrate`, `last10`, etc.
1. After predicting all game matches' results, we push the eastern and western top 8 team names into `sim_record_East` and `sim_record_West`, also we add these 16 teams' counters by one in `sim_record_number`. 
1. Repeat step 2, 3 for 1000 times.
1. Finally, we could get `sim_record_number` after 1000 times simulation. And for our final prediction, we could count total scores for all teams. Let $$Total\ score = times\ of\ 1^{st} \times 8+\ times\ of\ 2^{nd} \times 7+...+\ times\ of\ 8^{th} \times 1$$. We could get the rankings in order of total scores from largest to smallest. And the top 8 western and eastern teams are what we finally want.

Code for making simulations can be found below in **Appendix**.

# Results

After doing 1000 simulations, we can plot the times each team finally ranked the top8 in each simulation, with different color representing different rank. The graphs for different conference are showed below and here are some obvious facts:

- For east conference, team **TOR**, **BOS**, **PHI**, **CLE**, **IND**, **MIA** and **MIL** can be in playoff in most of the simulations. Also, team **TOR** and **BOS** are in playoff 1000 times, but the times that team **TOR** ranked the first is greater than team **BOS**.
- For west conference, team **HOU**, **GS**, **POR** and **UTA** can be in playoff in most of the simulations. Also, team **HOU** and **GS** are in playoff 1000 times, but the times that team **HOU** ranked the first is greater than team **GS**.

```{r, echo = FALSE, message = FALSE}
library("ggplot2")
library("tidyr")
data_sim = read.csv("simulation results.csv")
data_sim = data_sim[,-1]
colnames(data_sim)[3:10] = c("1st", "2nd", "3rd", "4th", "5th", "6th", "7th", "8th")
data_sim2 = gather(data_sim, "1st", "2nd", "3rd", "4th", "5th", "6th", "7th", "8th", key = "rank", value = "times")
data_sim2_west = data_sim2[data_sim2$confname == "West",]
data_sim2_east = data_sim2[data_sim2$confname == "East",]
ggplot(data_sim2_east) + aes(x = teamname, y = times, fill = rank) + geom_bar(stat = "identity") + labs(title = "East Conference")
ggplot(data_sim2_west) + aes(x = teamname, y = times, fill = rank) + geom_bar(stat = "identity") + labs(title = "West Conference")
```

\newpage

After calculating the total scores, our final prediction for playoff teams in 2017-18 season with the specific rank is: 

```{r, echo = FALSE}
library(kableExtra)
result_table_1 = as.data.frame(matrix(NA, 8, 4))
rownames(result_table_1) = c("1st", "2nd", "3rd", "4th", "5th", "6th", "7th", "8th")
colnames(result_table_1) = c("Predicted_East", "Actual_East", "Predicted_West", "Actual_West")
Predicted_East = data_sim$teamname[data_sim$confname == "East"]
result_table_1$Predicted_East = Predicted_East[1:8]
Predicted_West = data_sim$teamname[data_sim$confname == "West"]
result_table_1$Predicted_West = Predicted_West[1:8]
result_table_1$Actual_East = c("TOR", "BOS", "PHI", "CLE", "IND", "MIA", "MIL", "WAS")
result_table_1$Actual_West = c("HOU", "GS", "POR", "OKC", "UTA", "NO", "SA", "MIN")
kable(result_table_1) %>% kable_styling(position = "center")
```

- We found that among all 16 actual playoff teams in 2017-18 season, we correctly predicted 14 teams, so our accuracy is $\frac{14}{16} = 87.5\%$.
- In addition, when considering the rank for all 16 actual teams, we make correct prediction for 6 Eastern teams and 3 Western teams, which further increase the reliability of our results.

# Discussion

## For the permutation test:
The test for correlation is not very accurate because the "Last 10" data (i.e. `homeTeamlast10` and `awayTeamlast10`) are highly categorical (discrete) because based on their calculation criteria: the number of times the team wins, which is an integer, divided by 10. When the "Last 10" data is paired with the other continuous variables, such as `homeTeamRate` and `histRate`, the correlation between a continuous variable and a somewhat discrete variable cannot be simply determined by correlation coefficients.

we use the Pearson correlation and Spearman correlation two methods to calculate the correlation between two variables. But that may be not enough and accurate. We can use more methods to calculate correlations according to different variable kinds. 


## For the result itself:

Our prediction, in comparing to the real final standing by the end of season 17-18, get 100% success in predicting the 8 Eastern teams entering the playoffs while 6 out of 8 teams correct in the West conference: 

* DEN and LAC did not get into the playoffs
* NO and SA took their places instead.

Apart from improvements could make in our data processing, we found that unpredictable injury and tradings, which we have not considered in our model, may have strongly affected the real final result. The possible factors include:

1. DEN’s main point guard Harris was claimed to be injured on March 18, when is almost the end of the regular season.
1. DEN’s main power forward Millsap rejoin the team in the mid-season and not perform well during the first several months after he rejoins.
1. LAC traded its main power forward Griffin in the mid-season, gave up their fighting for the playoff and started the team’s rebuilt.
1. The 4th to 10th teams in the West are very competitive with each other. Their win rates are only 2% different at most.


<!-- Force a new page for appendix -->
\newpage

# Appendix

### Scatterplots for Correlation

```{r, eval = FALSE}
data = read.csv("data_fit.csv")

par(mfrow = c(2,2))
plot(data$homeTeamRate, jitter(data$homeTeamlast10, 3), main = "Home Rate vs. Home Last 10")
plot(data$awayTeamRate, jitter(data$awayTeamlast10, 3), main = "Away Rate vs. Away Last 10")
plot(data$homeTeamRate, data$histRate, main = "Home Rate vs. Historical Rate")
plot(data$awayTeamRate, data$histRate, main = "Away Rate vs. Historical Rate")
par(mfrow = c(2,2))
plot(jitter(data$homeTeamlast10, 3), data$histRate, main = "Home Last 10 vs. Historical Rate")
plot(jitter(data$awayTeamlast10, 3), data$histRate, main = "Away Last 10 vs. Historical Rate")
plot(data$homeTeamRate, data$awayTeamRate, main = "Home Rate vs. Away Rate")
plot(jitter(data$homeTeamlast10, 3), jitter(data$awayTeamlast10, 3), 
     main = "Home Last 10 vs. Away Last 10")
par(mfrow = c(2,2))
plot(data$homeTeamRate, jitter(data$awayTeamlast10, 3), main = "Home Rate vs. Away Last 10")
plot(data$awayTeamRate, jitter(data$homeTeamlast10, 3), main = "Away Rate vs. Home Last 10")
```

### Permutation Test with either correlation coefficient
```{r, eval = FALSE, echo = TRUE}
perm_test = function(X, Y, B = 10000, method = "pearson") {
  nu = seq_along(X)
  reps = numeric(B)
  
  if (method == "pearson") { # Pearson Method - default
    rho0 = abs(cor(X, Y))
    for ( i in 1:B ) {
      perm = sample(nu, size = length(X), replace = FALSE)
      X1 = X[perm]
      reps[i] = abs(cor(X1, Y))
    }
    pval = mean(c(rho0, reps) >= rho0)
  } else if (method == "spearman") { # Spearman Method
    rho0 = cor(X, Y, method = "spearman")
    t0 = abs(rho0*sqrt((length(X) - 2)/(1 - rho0^2)))
    for ( i in 1:B ) {
      perm = sample(nu, size = length(X), replace = FALSE)
      X1 = X[perm]
      rho = cor(X1, Y, method = "spearman")
      reps[i] = abs(rho*sqrt((length(X) - 2)/(1 - rho^2)))
    }
    pval = mean(c(t0, reps) >= t0)
  }
  
  return(pval)
}

# running the tests
perm_test(data$homeTeamRate, data$homeTeamlast10, 10000, "pearson")
perm_test(data$awayTeamRate, data$awayTeamlast10, 10000, "pearson")
perm_test(data$homeTeamRate, data$histRate, 10000, "spearman")
perm_test(data$awayTeamRate, data$histRate, 10000, "spearman")
perm_test(data$homeTeamlast10, data$histRate, 10000, "spearman")
perm_test(data$awayTeamlast10, data$histRate, 10000, "spearman")
perm_test(data$homeTeamRate, data$awayTeamRate, 10000, "spearman")
perm_test(data$homeTeamlast10, data$awayTeamlast10, 10000, "spearman")
perm_test(data$homeTeamRate, data$awayTeamlast10, 10000, "spearman")
perm_test(data$awayTeamRate, data$homeTeamlast10, 10000, "spearman")
```

### Simulations
```{r, eval = FALSE}
totalNRows = nrow(data_B)
set.seed(665267179)

sim_record_East = as.data.frame(matrix(NA, 1000, 8))
colnames(sim_record_East) = c("1st", "2nd", "3rd", "4th", "5th", "6th", "7th", "8th")
sim_record_West = as.data.frame(matrix(NA, 1000, 8))
colnames(sim_record_West) = c("1st", "2nd", "3rd", "4th", "5th", "6th", "7th", "8th")
sim_record_number = as.data.frame(matrix(0, 30, 10))
colnames(sim_record_number) = c("teamname", "confname", 
                                "1st", "2nd", "3rd", "4th", 
                                "5th", "6th", "7th", "8th")
sim_record_number$teamname = team_level
sim_record_number$confname = data_A$confname

# simulating
sim_time = 1000
for (i in 1:sim_time) {
  data_A_copy = data_A
  data_B_copy = data_B
  #one-time simulation
  for (nrowdata_B_copy in 1:totalNRows) {
    homeTeam = data_B_copy[nrowdata_B_copy, ]$`HomeTeam(A)`
    awayTeam = data_B_copy[nrowdata_B_copy, ]$`AwayTeam(B)`
    
    homeTeamRow = which(data_A_copy$teamname == homeTeam)
    awayTeamRow = which(data_A_copy$teamname == awayTeam)
    
    homeTeamdata_A_copy = data_A_copy[homeTeamRow, 2:26]
    awayTeamdata_A_copy = data_A_copy[awayTeamRow, 2:26]
    
    data_B_copy[nrowdata_B_copy, ][6:30] = data_A_copy[homeTeamRow, ][2:26]
    data_B_copy[nrowdata_B_copy, ][31:55] = data_A_copy[awayTeamRow, ][2:26]
    
    homeTeamRate = homeTeamdata_A_copy[2][[1]]
    awayTeamRate = awayTeamdata_A_copy[3][[1]]
    homeTeamlast10 = homeTeamdata_A_copy[4][[1]]
    awayTeamlast10 = awayTeamdata_A_copy[4][[1]]
    histRate = data_B_copy[nrowdata_B_copy, ][5][[1]]
    
    predictorDataFrame = data.frame(homeTeamRate = homeTeamRate, 
                                    awayTeamRate = awayTeamRate, 
                                    homeTeamlast10 = homeTeamlast10,
                                    awayTeamlast10 = awayTeamlast10, 
                                    histRate = histRate)
    
    #predictStat = predict(glm1, predictorDataFrame)
    #ridge regression
    predictStat = predict.glmnet(rr, as.matrix(predictorDataFrame))
    [which(cv.out$lambda == cv.out$lambda.min)]
    
    threshold = exp(predictStat) / (1 + exp(predictStat))
    if (runif(1) < threshold) {
      result = 1
    } else {
      result = 0
    }
    
    data_B_copy[nrowdata_B_copy, ][56] = result
    
    homeRate = data_A_copy[homeTeamRow, ][3][[1]]
    homeMatch = data_A_copy[homeTeamRow, ][15][[1]]
    homeWinMatch = round(homeRate * homeMatch, digits=0)
    data_A_copy[homeTeamRow, ][15] = homeMatch + 1
    data_A_copy[homeTeamRow, ][3] = (homeWinMatch + result) / (homeMatch + 1)
    data_A_copy[homeTeamRow, ][18:26] = data_A_copy[homeTeamRow, ][17:25]
    data_A_copy[homeTeamRow, ][17] = data_B_copy[nrowdata_B_copy, ][56] + 1
    data_A_copy$last10[homeTeamRow] = sum(data_A_copy[homeTeamRow, 17:26] - 1) / 10
    
    
    awayRate = data_A_copy[awayTeamRow, ][4][[1]]
    awayMatch = data_A_copy[awayTeamRow, ][16][[1]]
    awayWinMatch = round(awayRate * awayMatch, digits=0)
    data_A_copy[awayTeamRow, ][16] = awayMatch + 1
    data_A_copy[awayTeamRow, ][4] = (awayWinMatch + (1 - result)) / (awayMatch + 1)
    data_A_copy[awayTeamRow, ][18:26] = data_A_copy[awayTeamRow, ][17:25]
    if (data_B_copy[nrowdata_B_copy, ][56] == 0) {
      data_A_copy[awayTeamRow, ][17] = 2
    } else {
      data_A_copy[awayTeamRow, ][17] = 1
    }
    data_A_copy$last10[awayTeamRow] = sum(data_A_copy[awayTeamRow, 17:26] - 1) / 10
    data_A_copy$totalmatch[homeTeamRow] = data_A_copy$totalmatch[homeTeamRow] + 1
    data_A_copy$totalmatch[awayTeamRow] = data_A_copy$totalmatch[awayTeamRow] + 1
  }
  
  # recording result
  data_A_copy_East = data_A_copy[data_A_copy$confname == "East",]
  data_A_copy_East = data_A_copy_East[order(
    -data_A_copy_East$homerate*data_A_copy_East$homematch
    -data_A_copy_East$awayrate*data_A_copy_East$awaymatch),]
  sim_record_East[i, ] = data_A_copy_East$teamname[1:8]
  
  data_A_copy_West = data_A_copy[data_A_copy$confname == "West",]
  data_A_copy_West = data_A_copy_West[order(
    -data_A_copy_West$homerate*data_A_copy_West$homematch
    -data_A_copy_West$awayrate*data_A_copy_West$awaymatch),] 
  sim_record_West[i, ] = data_A_copy_West$teamname[1:8]
  
  for (rank in 1:8) {
    sim_record_number[which(sim_record_number$teamname == 
                              data_A_copy_East$teamname[rank]), rank + 2] = 
      sim_record_number[which(sim_record_number$teamname == 
                                data_A_copy_East$teamname[rank]), rank + 2] + 1
    sim_record_number[which(sim_record_number$teamname == 
                              data_A_copy_West$teamname[rank]), rank + 2] = 
      sim_record_number[which(sim_record_number$teamname == 
                                data_A_copy_West$teamname[rank]), rank + 2] + 1
  }
}

sim_record_number$total = rowSums(sim_record_number[,3:10])
sim_record_number$weightedtotal = sim_record_number$`1st`*8 +
  sim_record_number$`2nd`*7 + sim_record_number$`3rd`*6 +
  sim_record_number$`4th`*5 + sim_record_number$`5th`*4 +
  sim_record_number$`6th`*3 + sim_record_number$`7th`*2 + 
  sim_record_number$`8th`
sim_record_number = sim_record_number[order(sim_record_number$confname, 
                                            -sim_record_number$weightedtotal),]
write.csv(sim_record_number, "stat428_group6/simulation results.csv")
```

